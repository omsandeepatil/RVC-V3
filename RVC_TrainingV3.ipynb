{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elW4YTJ3cVlM"
      },
      "source": [
        "#**RVC Jugaad**\n",
        "\n",
        "Breaking news from the tech rebellion front: Google has slapped an official ban on the RVC repository, claiming it's causing more ruckus than a toddler in a candy store. But fear not, brave souls, for I have decided to take matters into my own hands and pull off a jailbreak that even Houdini would envy! Armed with the mighty Easy 10/25 and a sprinkle of basic commands, I'm on a mission to unban RVC and unleash the power of custom models for all, because who needs restrictions when you can have fun with AI?\n",
        "\n",
        "Join the rebellion on my GitHub: https://github.com/omsandeepatil/\n",
        "\n",
        "Get a front-row seat to the tech magic with Easy 10/25: https://colab.research.google.com/drive/1r4IRL0UA7JEoZ0ZK8PKfMyTIBHKpyhcw\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKjJYciIZIx-",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Install Dependencies\n",
        "!pip3 install faiss-cpu==1.7.2\n",
        "!pip3 install fairseq gradio==3.14.0\n",
        "!pip3 install ffmpeg\n",
        "!pip3 install ffmpeg-python\n",
        "!pip3 install praat-parselmouth\n",
        "!pip3 install pyworld numpy==1.23.5\n",
        "!pip3 install numba==0.56.4\n",
        "!pip3 install librosa==0.9.2\n",
        "!pip install gdown\n",
        "!gdown https://drive.google.com/file/d/1NOtvnwv6GTdGhc5pqT046RIfKK9Iw_Md/view?usp=sharing -O /content/ --fuzzy\n",
        "%cd /content/\n",
        "!unzip  DeepFakeV3.zip\n",
        "!pip install python-dotenv\n",
        "!pip  install -r /content/DeepFakeV3/requirements.txt\n",
        "!rm /content/DeepFakeV3.zip\n",
        "%cd /content/DeepFakeV3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PgtNmc9_aw5W"
      },
      "outputs": [],
      "source": [
        "#@title 1.Preprocess Data\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "from ipywidgets import Button\n",
        "%cd /content/DeepFakeV2/\n",
        "model_name = 'modiji' #@param {type:\"string\"}\n",
        "#@markdown <small> Enter the path to your dataset, or if you want just upload the audios using the File Manager into the 'dataset' folder.\n",
        "dataset_folder = '/content/drive/MyDrive/Project/Deepfake/Datasets/RVC' #@param {type:\"string\"}\n",
        "while len(os.listdir(dataset_folder)) < 1:\n",
        "    input(\"Your dataset folder is empty.\")\n",
        "!mkdir -p ./logs/{model_name}\n",
        "with open(f'./logs/{model_name}/preprocess.log','w') as f:\n",
        "    print(\"Starting...\")\n",
        "!python infer/modules/train/preprocess.py {dataset_folder} 40000 2 ./logs/{model_name} False 3.0 > /dev/null 2>&1\n",
        "with open(f'./logs/{model_name}/preprocess.log','r') as f:\n",
        "    if 'end preprocess' in f.read():\n",
        "        clear_output()\n",
        "        display(Button(description=\"\\u2714 Success\", button_style=\"success\"))\n",
        "    else:\n",
        "        print(\"Error preprocessing data... Make sure your dataset folder is correct.\")\n",
        "f0method = \"harvest\" # @param [\"pm\", \"harvest\", \"rmvpe\", \"rmvpe_gpu\"]\n",
        "!mkdir /content/drive/MyDrive/RVC/{model_name}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c9d6f8dd7cce48209743dc3fed58841d"
          ]
        },
        "id": "fMf6iAqHk68w",
        "outputId": "3cb872df-c381-4134-a907-a26962c3314d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c9d6f8dd7cce48209743dc3fed58841d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Button(button_style='success', description='✔ Success', style=ButtonStyle())"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title 2. Feature Index\n",
        "%cd /content/DeepFakeV2/\n",
        "with open(f'./logs/{model_name}/extract_f0_feature.log','w') as f:\n",
        "    print(\"Starting...\")\n",
        "if f0method != \"rmvpe_gpu\":\n",
        "    !python infer/modules/train/extract/extract_f0_print.py ./logs/{model_name} 2 {f0method}\n",
        "else:\n",
        "    !python infer/modules/train/extract/extract_f0_rmvpe.py 1 0 0 ./logs/{model_name} True\n",
        "!python infer/modules/train/extract_feature_print.py cuda:0 1 0 0 ./logs/{model_name} v2\n",
        "with open(f'./logs/{model_name}/extract_f0_feature.log','r') as f:\n",
        "    if 'all-feature-done' in f.read():\n",
        "        clear_output()\n",
        "        display(Button(description=\"\\u2714 Success\", button_style=\"success\"))\n",
        "    else:\n",
        "        print(\"Error preprocessing data... Make sure your data was preprocessed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "158dd4d2e2ff4c98a4625270131ce30b"
          ]
        },
        "id": "3KyMRbK49g__",
        "outputId": "08c5909e-efe0-489f-d715-f3336f76eb0a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "158dd4d2e2ff4c98a4625270131ce30b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Button(button_style='success', description='✔ Success', style=ButtonStyle())"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title 3.Train Index\n",
        "import numpy as np\n",
        "import faiss\n",
        "%cd /content/DeepFakeV2\n",
        "def train_index(exp_dir1, version19):\n",
        "    exp_dir = \"logs/%s\" % (exp_dir1)\n",
        "    os.makedirs(exp_dir, exist_ok=True)\n",
        "    feature_dir = (\n",
        "        \"%s/3_feature256\" % (exp_dir)\n",
        "        if version19 == \"v1\"\n",
        "        else \"%s/3_feature768\" % (exp_dir)\n",
        "    )\n",
        "    if not os.path.exists(feature_dir):\n",
        "        return \"请先进行特征提取!\"\n",
        "    listdir_res = list(os.listdir(feature_dir))\n",
        "    if len(listdir_res) == 0:\n",
        "        return \"请先进行特征提取！\"\n",
        "    infos = []\n",
        "    npys = []\n",
        "    for name in sorted(listdir_res):\n",
        "        phone = np.load(\"%s/%s\" % (feature_dir, name))\n",
        "        npys.append(phone)\n",
        "    big_npy = np.concatenate(npys, 0)\n",
        "    big_npy_idx = np.arange(big_npy.shape[0])\n",
        "    np.random.shuffle(big_npy_idx)\n",
        "    big_npy = big_npy[big_npy_idx]\n",
        "    if big_npy.shape[0] > 2e5:\n",
        "        infos.append(\"Trying doing kmeans %s shape to 10k centers.\" % big_npy.shape[0])\n",
        "        yield \"\\n\".join(infos)\n",
        "        try:\n",
        "            big_npy = (\n",
        "                MiniBatchKMeans(\n",
        "                    n_clusters=10000,\n",
        "                    verbose=True,\n",
        "                    batch_size=256 * config.n_cpu,\n",
        "                    compute_labels=False,\n",
        "                    init=\"random\",\n",
        "                )\n",
        "                .fit(big_npy)\n",
        "                .cluster_centers_\n",
        "            )\n",
        "        except:\n",
        "            info = traceback.format_exc()\n",
        "            logger.info(info)\n",
        "            infos.append(info)\n",
        "            yield \"\\n\".join(infos)\n",
        "\n",
        "    np.save(\"%s/total_fea.npy\" % exp_dir, big_npy)\n",
        "    n_ivf = min(int(16 * np.sqrt(big_npy.shape[0])), big_npy.shape[0] // 39)\n",
        "    infos.append(\"%s,%s\" % (big_npy.shape, n_ivf))\n",
        "    yield \"\\n\".join(infos)\n",
        "    index = faiss.index_factory(256 if version19 == \"v1\" else 768, \"IVF%s,Flat\" % n_ivf)\n",
        "    infos.append(\"training\")\n",
        "    yield \"\\n\".join(infos)\n",
        "    index_ivf = faiss.extract_index_ivf(index)  #\n",
        "    index_ivf.nprobe = 1\n",
        "    index.train(big_npy)\n",
        "    faiss.write_index(\n",
        "        index,\n",
        "        \"%s/trained_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n",
        "        % (exp_dir, n_ivf, index_ivf.nprobe, exp_dir1, version19),\n",
        "    )\n",
        "\n",
        "    infos.append(\"adding\")\n",
        "    yield \"\\n\".join(infos)\n",
        "    batch_size_add = 8192\n",
        "    for i in range(0, big_npy.shape[0], batch_size_add):\n",
        "        index.add(big_npy[i : i + batch_size_add])\n",
        "    faiss.write_index(\n",
        "        index,\n",
        "        \"%s/added_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n",
        "        % (exp_dir, n_ivf, index_ivf.nprobe, exp_dir1, version19),\n",
        "    )\n",
        "    infos.append(\n",
        "        \"成功构建索引，added_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n",
        "        % (n_ivf, index_ivf.nprobe, exp_dir1, version19)\n",
        "    )\n",
        "\n",
        "training_log = train_index(model_name, 'v2')\n",
        "\n",
        "for line in training_log:\n",
        "    print(line)\n",
        "    if 'adding' in line:\n",
        "        clear_output()\n",
        "        display(Button(description=\"\\u2714 Success\", button_style=\"success\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FFfC9x239kC1"
      },
      "outputs": [],
      "source": [
        "#@title 4.Train Model\n",
        "%cd /content/DeepFakeV2\n",
        "from random import shuffle\n",
        "import json\n",
        "import os\n",
        "import pathlib\n",
        "from subprocess import Popen, PIPE, STDOUT\n",
        "now_dir=os.getcwd()\n",
        "#@markdown <small> Enter the name of your model again. It must be the same you chose before.\n",
        "model_name = 'modiji'#@param {type:\"string\"}\n",
        "#@markdown <small> Choose how often to save the model and how much training you want it to have.\n",
        "save_frequency = 30 # @param {type:\"slider\", min:5, max:50, step:5}\n",
        "epochs = 210 # @param {type:\"slider\", min:10, max:1000, step:10}\n",
        "#@markdown <small> ONLY cache datasets under 10 minutes long. Otherwise leave this unchecked.\n",
        "cache = False #@param {type:\"boolean\"}\n",
        "# Remove the logging setup\n",
        "\n",
        "def click_train(\n",
        "    exp_dir1,\n",
        "    sr2,\n",
        "    if_f0_3,\n",
        "    spk_id5,\n",
        "    save_epoch10,\n",
        "    total_epoch11,\n",
        "    batch_size12,\n",
        "    if_save_latest13,\n",
        "    pretrained_G14,\n",
        "    pretrained_D15,\n",
        "    gpus16,\n",
        "    if_cache_gpu17,\n",
        "    if_save_every_weights18,\n",
        "    version19,\n",
        "):\n",
        "    # 生成filelist\n",
        "    exp_dir = \"%s/logs/%s\" % (now_dir, exp_dir1)\n",
        "    os.makedirs(exp_dir, exist_ok=True)\n",
        "    gt_wavs_dir = \"%s/0_gt_wavs\" % (exp_dir)\n",
        "    feature_dir = (\n",
        "        \"%s/3_feature256\" % (exp_dir)\n",
        "        if version19 == \"v1\"\n",
        "        else \"%s/3_feature768\" % (exp_dir)\n",
        "    )\n",
        "    if if_f0_3:\n",
        "        f0_dir = \"%s/2a_f0\" % (exp_dir)\n",
        "        f0nsf_dir = \"%s/2b-f0nsf\" % (exp_dir)\n",
        "        names = (\n",
        "            set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)])\n",
        "            & set([name.split(\".\")[0] for name in os.listdir(feature_dir)])\n",
        "            & set([name.split(\".\")[0] for name in os.listdir(f0_dir)])\n",
        "            & set([name.split(\".\")[0] for name in os.listdir(f0nsf_dir)])\n",
        "        )\n",
        "    else:\n",
        "        names = set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)]) & set(\n",
        "            [name.split(\".\")[0] for name in os.listdir(feature_dir)]\n",
        "        )\n",
        "    opt = []\n",
        "    for name in names:\n",
        "        if if_f0_3:\n",
        "            opt.append(\n",
        "                \"%s/%s.wav|%s/%s.npy|%s/%s.wav.npy|%s/%s.wav.npy|%s\"\n",
        "                % (\n",
        "                    gt_wavs_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    feature_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    f0_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    f0nsf_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    spk_id5,\n",
        "                )\n",
        "            )\n",
        "        else:\n",
        "            opt.append(\n",
        "                \"%s/%s.wav|%s/%s.npy|%s\"\n",
        "                % (\n",
        "                    gt_wavs_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    feature_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    spk_id5,\n",
        "                )\n",
        "            )\n",
        "    fea_dim = 256 if version19 == \"v1\" else 768\n",
        "    if if_f0_3:\n",
        "        for _ in range(2):\n",
        "            opt.append(\n",
        "                \"%s/logs/mute/0_gt_wavs/mute%s.wav|%s/logs/mute/3_feature%s/mute.npy|%s/logs/mute/2a_f0/mute.wav.npy|%s/logs/mute/2b-f0nsf/mute.wav.npy|%s\"\n",
        "                % (now_dir, sr2, now_dir, fea_dim, now_dir, now_dir, spk_id5)\n",
        "            )\n",
        "    else:\n",
        "        for _ in range(2):\n",
        "            opt.append(\n",
        "                \"%s/logs/mute/0_gt_wavs/mute%s.wav|%s/logs/mute/3_feature%s/mute.npy|%s\"\n",
        "                % (now_dir, sr2, now_dir, fea_dim, spk_id5)\n",
        "            )\n",
        "    shuffle(opt)\n",
        "    with open(\"%s/filelist.txt\" % exp_dir, \"w\") as f:\n",
        "        f.write(\"\\n\".join(opt))\n",
        "\n",
        "    # Replace logger.debug, logger.info with print statements\n",
        "    print(\"Write filelist done\")\n",
        "    print(\"Use gpus:\", str(gpus16))\n",
        "    if pretrained_G14 == \"\":\n",
        "        print(\"No pretrained Generator\")\n",
        "    if pretrained_D15 == \"\":\n",
        "        print(\"No pretrained Discriminator\")\n",
        "    if version19 == \"v1\" or sr2 == \"40k\":\n",
        "        config_path = \"configs/v1/%s.json\" % sr2\n",
        "    else:\n",
        "        config_path = \"configs/v2/%s.json\" % sr2\n",
        "    config_save_path = os.path.join(exp_dir, \"config.json\")\n",
        "    if not pathlib.Path(config_save_path).exists():\n",
        "        with open(config_save_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            with open(config_path, \"r\") as config_file:\n",
        "                config_data = json.load(config_file)\n",
        "                json.dump(\n",
        "                    config_data,\n",
        "                    f,\n",
        "                    ensure_ascii=False,\n",
        "                    indent=4,\n",
        "                    sort_keys=True,\n",
        "                )\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "    cmd = (\n",
        "        'python infer/modules/train/train.py -e \"%s\" -sr %s -f0 %s -bs %s -g %s -te %s -se %s %s %s -l %s -c %s -sw %s -v %s'\n",
        "        % (\n",
        "            exp_dir1,\n",
        "            sr2,\n",
        "            1 if if_f0_3 else 0,\n",
        "            batch_size12,\n",
        "            gpus16,\n",
        "            total_epoch11,\n",
        "            save_epoch10,\n",
        "            \"-pg %s\" % pretrained_G14 if pretrained_G14 != \"\" else \"\",\n",
        "            \"-pd %s\" % pretrained_D15 if pretrained_D15 != \"\" else \"\",\n",
        "            1 if if_save_latest13 == True else 0,\n",
        "            1 if if_cache_gpu17 == True else 0,\n",
        "            1 if if_save_every_weights18 == True else 0,\n",
        "            version19,\n",
        "        )\n",
        "    )\n",
        "    # Use PIPE to capture the output and error streams\n",
        "    p = Popen(cmd, shell=True, cwd=now_dir, stdout=PIPE, stderr=STDOUT, bufsize=1, universal_newlines=True)\n",
        "\n",
        "    # Print the command's output as it runs\n",
        "    for line in p.stdout:\n",
        "        print(line.strip())\n",
        "\n",
        "    # Wait for the process to finish\n",
        "    p.wait()\n",
        "    return \"训练结束, 您可查看控制台训练日志或实验文件夹下的train.log\"\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./logs\n",
        "training_log = click_train(\n",
        "    model_name,\n",
        "    '40k',\n",
        "    True,\n",
        "    0,\n",
        "    save_frequency,\n",
        "    epochs,\n",
        "    7,\n",
        "    True,\n",
        "    'assets/pretrained_v2/f0G40k.pth',\n",
        "    'assets/pretrained_v2/f0D40k.pth',\n",
        "    0,\n",
        "    cache,\n",
        "    True,\n",
        "    'v2',\n",
        ")\n",
        "print(training_log)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5. Save model progress\n",
        "!mkdir /content/drive/MyDrive/RVC/{model_name}\n",
        "!mkdir /content/drive/MyDrive/RVC/weights/\n",
        "!cp /content/DeepFakeV3/assets/weights/*.pth /content/drive/MyDrive/RVC/weights/\n",
        "!cp  /content/DeepFakeV3/logs/{model_name}/D_2333333.pth /content/drive/MyDrive/RVC/{model_name}/\n",
        "!cp /content/DeepFakeV3/logs/{model_name}/G_2333333.pth /content/drive/MyDrive/RVC/{model_name}/\n",
        "!cp /content/DeepFakeV3/logs/{model_name}/added_IVF3534_Flat_nprobe_1_modiji_v2.index /content/drive/MyDrive/RVC/{model_name}/\n",
        "!cp /content/DeepFakeV3/logs/{model_name}/trained_IVF3534_Flat_nprobe_1_modiji_v2.index /content/drive/MyDrive/RVC/{model_name}/"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cxSBNAL5oe4j"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}